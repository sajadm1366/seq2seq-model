{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace022f0-47b9-4682-8119-a50b9044cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "from seq2seq import Seq2seq\n",
    "import os\n",
    "from collections import Counter\n",
    "from dataset_gen import *\n",
    "import re\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07bb3f-c7a9-4397-bb3d-889aeb7f77e9",
   "metadata": {},
   "source": [
    "Build dictionary for source and target. Note thae path is the same as in the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf0c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = load_data_gen(dataset_path_name=\"path\")\n",
    "\n",
    "get_vocab = GetVocab(data_gen)\n",
    "vocab_source, vocab_target = get_vocab.tr_get_vocab(replace_char)\n",
    "\n",
    "\n",
    "max_len = 10\n",
    "preprocess = Preprocess(data_gen, vocab_source, vocab_target, max_len)\n",
    "transform_gen = preprocess.transform\n",
    "\n",
    "\n",
    "vocab_size_src = len(vocab_source)\n",
    "vocab_size_trg = len(vocab_target)\n",
    "        \n",
    "        \n",
    "target_token2word = {val: key for key, val in vocab_target.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f9606-80b6-4fa6-ba12-375eb42a0c2a",
   "metadata": {},
   "source": [
    "Take a source sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4579d68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([6.000e+01, 1.100e+02, 1.450e+02, 1.874e+03, 5.290e+02, 5.250e+02,\n",
       "       2.718e+03, 1.260e+02, 1.000e+00, 0.000e+00], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_sentence = ProcessSentence(vocab_source, vocab_target, max_len)\n",
    "\n",
    "source_token, _ = process_sentence.tokenize(\"Tom is a much better liar than you\", lang=\"eng\")\n",
    "source_token = tf.constant(source_token, dtype=tf.float32)\n",
    "source_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7db1ebc-ea19-47cc-bdf9-2d1b2c97847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seq(vocab_size_src, vocab_size_trg, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94db3d6-d896-4c98-ac88-1f0632130da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1b54f3df460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"saved_model/seq2seq_weights\").expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b1db81-0531-4188-bcc4-1ab14a699d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tom est un meilleur menteur que vous . . .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(source_token, target_token2word, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ac62f-4e29-4c6c-8ced-b396e727ebe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}